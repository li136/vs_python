- FPN主要解决的是物体检测中的多尺度问题，通过简单的网络连接改变，在基本不增加原有模型计算量的情况下，大幅度提升了小物体检测的性能。
```bash
低层的特征语义信息比较少，但是目标位置准确；高层的特征语义信息比较丰富，但是目标位置比较粗略。另外虽然也有些算法采用多尺度特征融合的方式，但是一般是采用融合后的特征做预测，而本文FPN不一样的地方在于预测是在不同特征层独立进行的。 
```
```bash
很多网络是自底向上卷积，然后使用最后一层特征图进行预测，像SPP-Net，Fast R-CNN，Faster R-CNN就是采用这种方式，即仅采用网络最后一层的特征。

以VGG16为例子，假如feat_stride=16，表示若原图大小是1000*600，经过网络后最深一层的特征图大小是60*40，可理解为特征图上一像素点映射原图中一个16*16的区域；那原图中有一个小于16*16大小的小物体，是不是就会被忽略掉，检测不到了呢？

所以这类网络的缺点就是会造成检测小物体的性能急剧下降。
```
![avatar](笔记整理\img\FPN1.jpg)
```bash
(a) Featurized image pyramid：这种方式就是先把图片弄成不同尺寸的，然后再对每种尺寸的图片提取不同尺度的特征，再对每个尺度的特征都进行单独的预测，这种方式的优点是不同尺度的特征都可以包含很丰富的语义信息，但是缺点就是时间成本太高。

(b) Pyramid feature hierarchy：这是SSD采用的多尺度融合的方法，即从网络不同层抽取不同尺度的特征，然后在这不同尺度的特征上分别进行预测，这种方法的优点在于它不需要额外的计算量。而缺点就是有些尺度的特征语义信息不是很丰富，此外，SSD没有用到足够低层的特征，作者认为低层的特征对于小物体检测是非常有帮助的。

(c) Single feature map：这是在SPPnet，Fast R-CNN，Faster R-CNN中使用的，就是在网络的最后一层的特征图上进行预测。这种方法的优点是计算速度会比较快，但是缺点就是最后一层的特征图分辨率低，不能准确的包含物体的位置信息。
```
![avatar](笔记整理\img\FPN2.jpg)
```bash
让低层高分辨率低语义的特征和高层低分辨率高语义的特征融合在一起，使得最终得到的不同尺度的特征图都有丰富的语义信息

特征金字塔的结构主要包括三个部分：bottom-up，top-down和lateral connection。
```
```bash
Bottom-up的过程就是将图片输入到backbone ConvNet中提取特征的过程中。Backbone输出的feature map的尺寸有的是不变的，有的是成2倍的减小的。对于那些输出的尺寸不变的层，把他们归为一个stage，那么每个stage的最后一层输出的特征就被抽取出来。
```
```bash
Top-down的过程就是将高层得到的feature map进行上采样然后往下传递，这样做是因为，高层的特征包含丰富的语义信息，经过top-down的传播就能使得这些语义信息传播到低层特征上，使得低层特征也包含丰富的语义信息。本文中，采样方法是最近邻上采样，使得特征图扩大2倍。上采样的目的就是放大图片，在原有图像像素的基础上在像素点之间采用合适的插值算法插入新的像素，在本文中使用的是最近邻上采样(插值)。这是最简单的一种插值方法，不需要计算，在待求像素的四个邻近像素中，将距离待求像素最近的邻近像素值赋给待求像素。
```
```bash
lateral connection主要包括三个步骤：

(1) 对于每个stage输出的feature map ，都先进行一个1*1的卷积降低维度。

(2) 然后再将得到的特征和上一层采样得到特征图  进行融合，就是直接相加，element-wise addition。因为每个stage输出的特征图之间是2倍的关系，所以上一层上采样得到的特征图的大小和本层的大小一样，就可以直接将对应元素相加 。

(3) 相加完之后需要进行一个3*3的卷积才能得到本层的特征输出 。使用这个3*3卷积的目的是为了消除上采样产生的混叠效应(aliasing effect)，混叠效应应该就是指上边提到的‘插值生成的图像灰度不连续，在灰度变化的地方可能出现明显的锯齿状’。在本文中，因为金字塔所有层的输出特征都共享classifiers/ regressors，所以输出的维度都被统一为256，即这些3*3的卷积的channel都为256。
```
```bash
```
```bash
```