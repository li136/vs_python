# 代码  
```bash
两个三维向量，但是第二维不一样，用广播机制变成两个四维向量相加
features = queries.unsqueeze(2) + keys.unsqueeze(1)
# queries的形状：(batch_size，num of queries，1，num_hidden)
# key的形状：(batch_size，1，num of keys，num_hiddens)
```
```bash
assert len(X.shape) in (2, 4)
#如果X.shape是2或4的话，继续执行，否则报错
```
```bash
modules = list(resnet.children())[:-2]
#移除linear and pool layers
```
```bash
#微调
def fine_tune(self, fine_tune=True):
    """
    Allow or prevent the computation of gradients for convolutional blocks 2 through 4 of the encoder.

    :param fine_tune: Allow?
    """
    for p in self.resnet.parameters():
        p.requires_grad = False
    # If fine-tuning, only fine-tune convolutional blocks 2 through 4
    for c in list(self.resnet.children())[5:]:
        for p in c.parameters():
            p.requires_grad = fine_tune
```
```bash
X = torch.ones((2, 1, 4))
Y = torch.ones((2, 4, 6))
# bmm也是矩阵乘法，2是批量
print(torch.bmm(X, Y).shape)
```
```bash
#测试repeat_interleave和matmul
a=torch.tensor([1.0,2.0,3.0])
b=a.repeat_interleave(3).reshape((-1, 3))
print(b)
c=b - torch.tensor([1.0,2.0,3.0])
print(c)
print(nn.functional.softmax(c,dim=1))
print(torch.matmul(b - torch.tensor([1.0,2.0,3.0]), a))
```
```bash
#unsqueeze()拓展维度，squeeze()对数据的维度进行压缩
print(weights.unsqueeze(1).shape)
```
```bash
# os.path.join()合并字符串
print(os.path.join('aaa','bbb','ccc.txt'))
```
```bash
# Remove linear and pool layers (since we're not doing classification)
modules = list(resnet.children())[:-2]
self.resnet = nn.Sequential(*modules)
```
```bash
为了加快训练过程，我们将利用DataLoader类的num_workers可选属性。
num_workers属性告诉DataLoader实例要使用多少个子进程进行数据加载。默认情况下，num_workers值被设置为0，0值代表告诉加载器在主进程内部加载数据。
这意味着训练进程将在主进程内部依次工作。在训练过程中使用一批批处理之后，我们从磁盘上读取另一批批处理数据。
现在，如果我们有一个工作进程，我们可以利用我们的机器有多个内核这一事实。这意味着，在主进程准备好另一个批处理的时候，下一个批处理已经可以加载并准备好了。这就是速度提升的原因。批批处理使用附加的辅助进程加载，并在内存中排队。
实验显示，在所有三个批次规模中，除了主流程外，拥有一个单一的工作流程可使速度提高约百分之二十。此外，在第一个流程之后增加额外的工作流程并没有真正显示出任何进一步的改进。
```
```bash
创建Dataloader时，pin_memory=True表示将load进的数据拷贝进锁页内存区，将内存中的Tensor转移至GPU cuda区会很快；pin_memory=False表示将load进数据放至非锁页内存区，速度会较慢。
当计算机的内存充足的时候，设置pin_memory=True。当系统卡住，或者交换内存使用过多的时候，设置pin_memory=False。因为pin_memory与电脑硬件性能有关，pytorch开发者不能确保每一个炼丹玩家都有高端设备，因此pin_memory默认为False。
```
```bash
Checkpoint是用于描述在每次训练后保存模型参数（权重）的惯例或术语。这就像在游戏中保存关卡时你可以随时通过加载保存文件回复游戏。你可以加载保存的模型权重重新开启训练甚至可以之后进行一个推理。
复杂模型的训练阶段通常很长（数小时到数天到数周）。在nushpc系统上，用于深度学习的GPU队列的默认时间限制为24小时，作业执行的最大时间限制为48小时。针对复杂模型和大型数据集的深度学习训练作业需要的训练时间可能比队列默认的限定时间要长很多。
因此，为了不丢失训练进度，建议在每个epoch或每个epoch中当它在当前这个point中是这个时间下的最好权重时执行模型参数（权重）的checkpoint。
在非易失性内存中保存最新或最佳权重是一种良好的做法，因为它允许您在给定的epoch保存进度副本，以防您想在任何给定的epoch调整超参数。它还允许您从任何有checkpoint的epoch恢复训练。如果作业或进程提前终止，可以通过从上次保存的checkpoint或任何其他checkpoint加载权重来恢复训练。
```
```bash
# 体会init_weights()和net.apply(init_weights)
import torch.nn as nn
import torch
@torch.no_grad()
def init_weights(m):
    # print(m)
    if type(m) == nn.Linear:
        m.weight.fill_(1.0)
        print(m.weight)
net = nn.Sequential(nn.Linear(2,4), nn.Linear(4, 8))
print(net)
print('isinstance torch.nn.Module',isinstance(net,torch.nn.Module))
print(' ')
net.apply(init_weights)
```
```bash
argparse.ArgumentParser
```